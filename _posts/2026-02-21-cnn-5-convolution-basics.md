---
layout: post
title: "CNN 5강 - 합성곱 신경망 기초"
description: "Convolution, Pooling, Receptive Field, Stride, Padding"
date: 2026-02-21
category: "Deep Learning"
subcategory: "CNN"
tags: deep-learning, cnn, convolution, pooling
comments: true
---

## 잘한 점

### 상황 1.
- **상황**: CNN의 핵심인 합성곱 연산을 처음 학습했다
- **액션**: 필터가 이미지 위를 슬라이딩하면서 특징을 추출하는 과정을 단계별로 따라갔다
- **칭찬**: 수식 없이 직관적으로 먼저 이해하고, 그 다음 수식을 대입한 점이 좋았다

---

## 개선점

### 상황 1.
- **문제**: 출력 크기 계산 공식이 헷갈린다
- **원인**: stride, padding 조합에 따른 출력 크기 변화를 충분히 연습하지 않았다
- **액션플랜**: 다양한 입력/필터/stride/padding 조합으로 출력 크기를 직접 계산해보기

---

## 배운 점

### 상황 1. 이미지 분류에서 선형 분류의 한계
- **배움**: 신경망을 통해 tensor를 계산하며, W를 계산하는 과정은 Back Propagation을 통해 Optimization을 한다. 선형 분류를 통해 이미지를 분류하는 것은 무리가 있다. 색 histogram 분포가 공간상 특징과 결합되어야 의미를 파악할 수 있지만, 선형 분류는 이미지의 공간성을 파괴한다. 그래서 여러 가지를 붙이는 것이 아니라 이미지의 end-to-end 네트워크를 설계해야 한다.
- **의미**: 이미지 분류에서 왜 단순 선형 분류가 아닌 CNN이 필요한지 근본적인 이유를 이해하게 되었다.

### 상황 2. CNN의 구성 요소
- **배움**: CNN은 Convolution, Subsampling, Pooling 등의 기법을 사용하며, 이를 통해 AlexNet을 만들었고 여러 Vision task에 사용되었다. 요즘에는 ViT가 나온 이후 CNN을 사용하지 않을 때도 있지만 여전히 많이 사용된다.
- **의미**: CNN의 역사적 맥락과 현재 위치를 파악함으로써 학습의 방향성을 잡을 수 있었다.

### 상황 3. Convolution Layer의 연산 과정
- **배움**:
  - 32 $\cdot$ 32 $\cdot$ 3 image를 5 $\cdot$ 5 $\cdot$ 3 filter로 convolution 한다.
  - convolution은 이미지 전체에 걸쳐 이동하면서 내적한 값의 합을 단일 스칼라 값으로 나타낸다.
  - 계산 시 32 $\cdot$ 32 $\cdot$ 3 $\times$ 5 $\cdot$ 5 $\cdot$ 3 = 28 $\cdot$ 28 $\cdot$ 1 로 계산된다.
  - 이러한 filter를 n개 갖고 연산한 뒤 출력 층을 28 $\cdot$ 28 $\cdot$ n (필터 개수)의 벡터 크기로 출력한다.
  - 따라서 내가 갖고 있는 이미지가 얼마나 filter와 fit한지에 대해 연산한다.
- **의미**: 합성곱 연산이 단순한 행렬 곱이 아니라, 필터를 슬라이딩하면서 내적하는 과정이라는 것을 직관적으로 이해할 수 있었다.

### 상황 4. 필터의 학습과 하이퍼파라미터
- **배움**: 어떤 filter와 fit하는지 알아야 하나? 그건 back prop과 optimize가 filter를 학습하면서 모델이 직접 배울 것이다. 하이퍼파라미터는 필터 크기와 필터 개수이다.
- **의미**: 필터의 값은 학습으로 결정되고, 사람이 정하는 것은 필터의 크기와 개수뿐이라는 역할 분담을 명확히 이해했다.

### 상황 5. Mini-batch와 입출력 텐서의 형태
- **배움**:
  - 이미지를 mini-batch로 계산하기 위해 이미지들을 묶어서 처리하므로 입력 데이터는 N $\cdot$ 3 $\cdot$ 32 $\cdot$ 32가 된다 (배치의 이미지 개수 * 채널의 개수(RGB니까 3차원) * 높이 * 길이).
  - 합성곱 연산 이후 출력 벡터의 크기는 N $\cdot$ n $\cdot$ 28 $\cdot$ 28 (배치의 이미지 개수 * 필터의 개수 * 높이 * 길이)가 된다.
  - 이미지의 규격은 (H $\cdot$ W $\cdot$ C $\cdot$ N) = (이미지 높이 $\cdot$ 이미지 넓이 $\cdot$ 채널 수(필터 수) $\cdot$ 미니배치 단위 수)이다.
- **의미**: 텐서의 차원 배치를 정확히 이해해야 실제 구현 시 shape 에러를 방지할 수 있다는 것을 알게 되었다.

### 상황 6. 다음 레이어 필터의 깊이
- **배움**: 다음 필터의 깊이(depth)는 이전 필터의 개수만큼을 가진다. 즉 위의 conv 연산 이후의 연산에서 필터는 5 $\cdot$ 5 $\cdot$ n의 크기를 갖게 된다. 그리고 해당 필터가 몇 개인지에 따라 출력 벡터의 깊이가 정해진다.
- **의미**: 레이어 간 연결에서 필터의 깊이가 자동으로 결정되는 구조를 이해함으로써 네트워크 설계의 원리를 파악했다.

### 상황 7. 활성화 함수와 Padding
- **배움**: Conv 연산만 하면 비선형성을 확보할 수 없으므로 활성화 함수를 추가해준다(ReLU). 또한 Conv 연산만 하면 데이터가 계속해서 작아지므로 이미지에 padding을 추가해준다 (테두리를 0으로 추가해주는 것이다).
- **의미**: Conv 연산 자체의 한계를 보완하기 위한 두 가지 핵심 테크닉(ReLU, zero padding)의 필요성을 이해했다.

### 상황 8. Receptive Field (수용 영역)
- **배움**:
  - receptive field는 심층 신경망이 왜 더 큰 구조의 학습이 가능한지를 설명한다.
  - 비선형성뿐만 아니라 conv 연산의 내재적 특성이기도 하다.
  - 첫 번째 conv 연산으로 출력된 feature map은 필터 크기와 비례한 국소적인 부분만을 나타낼 수 있다.
  - 그러나 네트워크가 깊어지고 conv 연산을 복수로 하게 될 경우 마지막 feature map의 원소들은 각각의 계층을 통과하며 필터 크기보다 더 큰 이미지 영역을 반영하게 된다.
  - 마지막 feature map 원소가 표현하는 영역이 점점 더 커지는 것을 의미한다.
- **의미**: 깊은 네트워크가 단순히 비선형성 때문만이 아니라, receptive field의 확장을 통해 더 넓은 맥락을 포착할 수 있다는 핵심 원리를 이해했다.

### 상황 9. Stride
- **배움**: stride는 필터의 이동 패턴이 연속적인 한 칸이 아니고 두 칸, 세 칸이 되어서 일부 영역을 건너뛰고 연산하는 것을 의미한다. stride를 통해 수용 영역을 효과적으로 더 크게 늘릴 수 있고 다운샘플링 효과 또한 존재한다.
- **의미**: stride가 단순히 연산량을 줄이는 것이 아니라, 수용 영역 확장과 다운샘플링이라는 두 가지 효과를 동시에 달성한다는 점을 알게 되었다.
